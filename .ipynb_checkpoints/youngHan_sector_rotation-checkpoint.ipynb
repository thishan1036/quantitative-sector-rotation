{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td70E9GEjOh3"
   },
   "source": [
    "Capstone Project\n",
    "\n",
    "Single Stage Relative Sector Rotation Model\n",
    "\n",
    "Objective:\n",
    "\n",
    "To develop and validate a quantitative model that ranks the 11 sector ETFs based on predicted relative performance. The final model will be used to construct a monthly rotating portfolio that aims to outperform benchmarks while managing regime risk.\n",
    "\n",
    "Dataset range: 2010-01-01 to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngLhQeK9jKaJ",
    "outputId": "123fd641-03cc-4163-f042-b608e5ed37e3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jua-KXuWjOQ_",
    "outputId": "13f67777-b7bc-4e51-e317-ad9bab9678e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_ta in /Users/young/opt/anaconda3/lib/python3.12/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas_ta) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas->pandas_ta) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas->pandas_ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas->pandas_ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
      "Requirement already satisfied: yfinance in /Users/young/opt/anaconda3/lib/python3.12/site-packages (0.2.65)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (4.25.3)\n",
      "Requirement already satisfied: websockets>=13.0 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: pycparser in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/young/opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_ta\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "BFm2-3rDbocY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.NaN = np.nan # this solved issue with pandas_ta\n",
    "import pandas_ta as ta\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "UR7oZKcwbtEI"
   },
   "outputs": [],
   "source": [
    "# internal function\n",
    "# checking data quality\n",
    "def quick_data_check(df, data_name = 'dataset'):\n",
    "  print(f\"{data_name}\")\n",
    "  print(f\"Shape of {data_name}: {df.shape}\")\n",
    "  print(f\"Data range: {df.index.min()} to {df.index.max()}\")\n",
    "  print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "  print(f\"Columns: {df.columns.tolist()}\")\n",
    "  return df.head(3), df.tail(3)\n",
    "\n",
    "# creating rolling features\n",
    "def create_rolling_features(series, windows=[20,60,200]):\n",
    "  features = {}\n",
    "  for window in windows:\n",
    "    features[f'ma_{window}'] = series.rolling(window=window).mean()\n",
    "    features[f'std_{window}'] = series.rolling(window=window).std()\n",
    "  return pd.DataFrame(features, index=series.index)\n",
    "\n",
    "# creating sector features\n",
    "def create_sector_features(price_series, windows=[20,60,200]):\n",
    "  features = {}\n",
    "  for window in windows:\n",
    "    features[f'sector_ma_{window}'] = price_series.rolling(window=window).mean()\n",
    "    features[f'sector_std_{window}'] = price_series.rolling(window=window).std()\n",
    "\n",
    "  features['returns_1m'] = price_series.pct_change(20)\n",
    "  features['returns_3m'] = price_series.pct_change(60)\n",
    "  features['volatility_20d'] = price_series.pct_change().rolling(20).std()*np.sqrt(252)\n",
    "  return pd.DataFrame(features, index=price_series.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt62B8f5oi-W"
   },
   "source": [
    "## Part 1.1\n",
    "\n",
    "### Data collection and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtFt87HKfBtL",
    "outputId": "dd7c7853-9caf-4cb1-8c9a-4e515fbd3df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from 2010-01-01 to 2025-07-31\n"
     ]
    }
   ],
   "source": [
    "# data collection\n",
    "start_date = '2010-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "print(f\"Collecting data from {start_date} to {end_date}\")\n",
    "\n",
    "sector_etf = {\n",
    "    'XLE': 'Energy',\n",
    "    'XLF': 'Financials',\n",
    "    'XLV': 'Health Care',\n",
    "    'XLI': 'Industrials',\n",
    "    'XLB': 'Materials',\n",
    "    'XLRE': 'Real Estate',\n",
    "    'XLK': 'Technology',\n",
    "    'XLC': 'Communication Services',\n",
    "    'XLY': 'Consumer Discretionary',\n",
    "    'XLP': 'Consumer Staples',\n",
    "    'XLU': 'Utilities'\n",
    "}\n",
    "\n",
    "benchmark = {\n",
    "    'SPY': 'S&P 500',\n",
    "    'SHY': '30-Year Treasury Bill'\n",
    "}\n",
    "\n",
    "macro_indicator = {\n",
    "    '^TNX': '10-Year Treasury',\n",
    "    'CL=F': 'WTI Crude Oil',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "He7scTkEfNUi",
    "outputId": "f7d2596c-2868-43ca-e953-5aa9597e593f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading XLE (Energy)\n",
      "XLE: 3917 rows downloaded\n",
      "Downloading XLF (Financials)\n",
      "XLF: 3917 rows downloaded\n",
      "Downloading XLV (Health Care)\n",
      "XLV: 3917 rows downloaded\n",
      "Downloading XLI (Industrials)\n",
      "XLI: 3917 rows downloaded\n",
      "Downloading XLB (Materials)\n",
      "XLB: 3917 rows downloaded\n",
      "Downloading XLRE (Real Estate)\n",
      "XLRE: 2466 rows downloaded\n",
      "Downloading XLK (Technology)\n",
      "XLK: 3917 rows downloaded\n",
      "Downloading XLC (Communication Services)\n",
      "XLC: 1788 rows downloaded\n",
      "Downloading XLY (Consumer Discretionary)\n",
      "XLY: 3917 rows downloaded\n",
      "Downloading XLP (Consumer Staples)\n",
      "XLP: 3917 rows downloaded\n",
      "Downloading XLU (Utilities)\n",
      "XLU: 3917 rows downloaded\n"
     ]
    }
   ],
   "source": [
    "# sector ETFs\n",
    "data = {}\n",
    "for ticker, name in sector_etf.items():\n",
    "  print(f\"Downloading {ticker} ({name})\")\n",
    "  try:\n",
    "    ticker_data = yf.download(ticker,\n",
    "                              start = start_date,\n",
    "                              end = end_date,\n",
    "                              progress=False)\n",
    "    data[ticker] = ticker_data\n",
    "    print(f\"{ticker}: {len(ticker_data)} rows downloaded\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error downloading {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKEq11Oghd7G",
    "outputId": "4ae1c7a4-23e4-4fc7-b2c0-c383623ffc70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SPY (S&P 500)\n",
      "SPY: 3917 rows downloaded\n",
      "Downloading SHY (30-Year Treasury Bill)\n",
      "SHY: 3917 rows downloaded\n"
     ]
    }
   ],
   "source": [
    "# benchmarks\n",
    "for ticker, name in benchmark.items():\n",
    "  print(f\"Downloading {ticker} ({name})\")\n",
    "  try:\n",
    "    ticker_data = yf.download(ticker,\n",
    "                              start = start_date,\n",
    "                              end = end_date,\n",
    "                              progress=False)\n",
    "    data[ticker] = ticker_data\n",
    "    print(f\"{ticker}: {len(ticker_data)} rows downloaded\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error downloading {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n5mMv17heN5",
    "outputId": "a1226535-56a9-480a-ca35-feb58ced5587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ^TNX (10-Year Treasury)\n",
      "^TNX: 3915 rows downloaded\n",
      "Downloading CL=F (WTI Crude Oil)\n",
      "CL=F: 3917 rows downloaded\n",
      "Total number of datasets: 15\n",
      "List of datasets: ['XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLC', 'XLY', 'XLP', 'XLU', 'SPY', 'SHY', '^TNX', 'CL=F']\n"
     ]
    }
   ],
   "source": [
    "# macro indicators\n",
    "for ticker, name in macro_indicator.items():\n",
    "  print(f\"Downloading {ticker} ({name})\")\n",
    "  try:\n",
    "    ticker_data = yf.download(ticker,\n",
    "                              start = start_date,\n",
    "                              end = end_date,\n",
    "                              progress=False)\n",
    "    data[ticker] = ticker_data\n",
    "    print(f\"{ticker}: {len(ticker_data)} rows downloaded\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error downloading {ticker}: {e}\")\n",
    "\n",
    "print(f\"Total number of datasets: {len(data)}\")\n",
    "print(f\"List of datasets: {list(data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wa_JuqeUnrvd",
    "outputId": "3771e173-7278-4ed6-c6c8-7bde40280630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Price Data\n",
      "Shape of Combined Price Data: (3919, 15)\n",
      "Data range: 2010-01-04 00:00:00 to 2025-07-30 00:00:00\n",
      "Missing values: 3612\n",
      "Columns: ['XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLC', 'XLY', 'XLP', 'XLU', 'SPY', 'SHY', '^TNX', 'CL=F']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  XLE       XLF        XLV        XLI        XLB  XLRE  \\\n",
       " Date                                                                     \n",
       " 2010-01-04  35.357689  9.049462  24.296618  21.140421  24.379665   NaN   \n",
       " 2010-01-05  35.646255  9.215791  24.058332  21.215071  24.458498   NaN   \n",
       " 2010-01-06  36.073147  9.234272  24.304302  21.259865  24.874134   NaN   \n",
       " \n",
       "                   XLK  XLC        XLY        XLP        XLU        SPY  \\\n",
       " Date                                                                     \n",
       " 2010-01-04  18.833551  NaN  24.759167  17.607052  18.151886  85.515617   \n",
       " 2010-01-05  18.809265  NaN  24.849947  17.613647  17.935795  85.742012   \n",
       " 2010-01-06  18.598833  NaN  24.882957  17.600449  18.040918  85.802376   \n",
       " \n",
       "                   SHY   ^TNX       CL=F  \n",
       " Date                                     \n",
       " 2010-01-04  67.847778  3.841  81.510002  \n",
       " 2010-01-05  67.929466  3.755  81.769997  \n",
       " 2010-01-06  67.937660  3.808  83.180000  ,\n",
       "                   XLE        XLF         XLV         XLI        XLB  \\\n",
       " Date                                                                  \n",
       " 2025-07-28  88.089996  53.070000  135.289993  154.509995  91.029999   \n",
       " 2025-07-29  88.949997  52.799999  134.429993  152.750000  90.680000   \n",
       " 2025-07-30  87.680000  52.700001  134.190002  152.000000  88.849998   \n",
       " \n",
       "                  XLRE         XLK         XLC         XLY        XLP  \\\n",
       " Date                                                                   \n",
       " 2025-07-28  42.049999  264.079987  107.040001  226.179993  80.660004   \n",
       " 2025-07-29  42.750000  264.089996  106.120003  224.619995  81.190002   \n",
       " 2025-07-30  42.150002  264.679993  106.449997  223.199997  80.470001   \n",
       " \n",
       "                   XLU         SPY        SHY   ^TNX       CL=F  \n",
       " Date                                                            \n",
       " 2025-07-28  83.620003  636.940002  82.540001  4.420  66.709999  \n",
       " 2025-07-29  84.580002  635.260010  82.610001  4.330  69.209999  \n",
       " 2025-07-30  85.209999  634.460022  82.519997  4.376  70.000000  )"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract adjusted close\n",
    "adj_close_prices = {}\n",
    "for ticker, ticker_data in data.items():\n",
    "    adj_close_prices[ticker] = ticker_data[('Close', ticker)]\n",
    "\n",
    "# create DataFrame\n",
    "df_data = pd.DataFrame(adj_close_prices)\n",
    "\n",
    "# validate dataset\n",
    "quick_data_check(df_data, \"Combined Price Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HocK-tGjBp2Z",
    "outputId": "93443457-cb2f-4a87-eff4-6479ebc99cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: \n",
      "XLC     2131\n",
      "XLRE    1453\n",
      "^TNX       4\n",
      "XLE        2\n",
      "XLF        2\n",
      "XLV        2\n",
      "XLI        2\n",
      "XLB        2\n",
      "XLK        2\n",
      "XLY        2\n",
      "XLP        2\n",
      "XLU        2\n",
      "SPY        2\n",
      "SHY        2\n",
      "CL=F       2\n",
      "dtype: int64\n",
      "\n",
      "XLE: 2010-01-04 00:00:00\n",
      "XLF: 2010-01-04 00:00:00\n",
      "XLV: 2010-01-04 00:00:00\n",
      "XLI: 2010-01-04 00:00:00\n",
      "XLB: 2010-01-04 00:00:00\n",
      "XLRE: 2015-10-08 00:00:00\n",
      "XLK: 2010-01-04 00:00:00\n",
      "XLC: 2018-06-19 00:00:00\n",
      "XLY: 2010-01-04 00:00:00\n",
      "XLP: 2010-01-04 00:00:00\n",
      "XLU: 2010-01-04 00:00:00\n",
      "SPY: 2010-01-04 00:00:00\n",
      "SHY: 2010-01-04 00:00:00\n",
      "^TNX: 2010-01-04 00:00:00\n",
      "CL=F: 2010-01-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# missing data analysis\n",
    "missing_val = df_data.isnull().sum().sort_values(ascending=False)\n",
    "print(f\"Missing values: \\n{missing_val}\\n\")\n",
    "\n",
    "for ticker in df_data.columns:\n",
    "  print(f\"{ticker}: {df_data[ticker].first_valid_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG33agJoEN9o"
   },
   "source": [
    "## Part 1.2\n",
    "\n",
    "### Missing data (XLC, XLRE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUvUqO_4FmDw"
   },
   "source": [
    "2 sector ETFs launched later than the other 9 ETFs and thus have missing data.\n",
    "- XLRE: launched 2015-10-08\n",
    " - real estate ETF existed before 2015 will be used as proxy for XLRE\n",
    "- XLC: launched 2018-06-19\n",
    " - top 10 holdings of XLC will be used as proxy for XLC before 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "so0i14BVFgGL",
    "outputId": "fc1686f3-6e8f-4490-c9e6-1d6c224176f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VNQ: available from 2010-01-04\n",
      "IYR: available from 2010-01-04\n",
      "FREL: available from 2015-02-05\n",
      "SCHH: available from 2011-01-13\n"
     ]
    }
   ],
   "source": [
    "# checking real estate ETFs availability\n",
    "real_estate = ['VNQ','IYR','FREL','SCHH']\n",
    "available_etf = []\n",
    "\n",
    "for etf in real_estate:\n",
    "  try:\n",
    "    test_data = yf.download(etf,\n",
    "                            start = '2010-01-01',\n",
    "                            end = '2015-10-07',\n",
    "                            progress=False)\n",
    "    if not test_data.empty:\n",
    "      available_etf.append(etf)\n",
    "      print(f\"{etf}: available from {test_data.index.date.min()}\")\n",
    "    else:\n",
    "      print(f\"{etf}: not available\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error downloading {etf}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H512n8GvS8Yb",
    "outputId": "7e5db628-3a24-46ab-e58a-f641fa79b789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between VNQ and XLRE: 0.988\n",
      "Correlation between IYR and XLRE: 0.991\n",
      "Correlation between VNQ returns and XLRE returns: 0.976\n",
      "Correlation between IYR returns and XLRE returns: 0.978\n",
      "Using IYR as proxy for XLRE\n"
     ]
    }
   ],
   "source": [
    "# choose between VNQ and IYR by comparing correlation with XLRE\n",
    "vnq = yf.download('VNQ',\n",
    "                  start = '2015-10-07',\n",
    "                  end = '2025-01-01',\n",
    "                  progress=False)\n",
    "iyr = yf.download('IYR',\n",
    "                  start = '2015-10-07',\n",
    "                  end = '2025-01-01',\n",
    "                  progress=False)\n",
    "xlre = yf.download('XLRE',\n",
    "                  start = '2015-10-07',\n",
    "                  end = '2025-01-01',\n",
    "                  progress=False)\n",
    "\n",
    "vnq_close = vnq['Close','VNQ']\n",
    "iyr_close = iyr['Close','IYR']\n",
    "xlre = df_data['XLRE'].loc['2015-10-07':'2025-01-01'].dropna()\n",
    "\n",
    "vnq_corr = vnq_close.corr(xlre)\n",
    "iyr_corr = iyr_close.corr(xlre)\n",
    "\n",
    "print(f\"Correlation between VNQ and XLRE: {vnq_corr:.3f}\")\n",
    "print(f\"Correlation between IYR and XLRE: {iyr_corr:.3f}\")\n",
    "\n",
    "vnq_return = vnq_close.pct_change().dropna()\n",
    "iyr_retutrn = iyr_close.pct_change().dropna()\n",
    "xlre_return = xlre.pct_change().dropna()\n",
    "\n",
    "vnq_ret_corr = vnq_return.corr(xlre_return)\n",
    "iyr_ret_corr = iyr_retutrn.corr(xlre_return)\n",
    "\n",
    "print(f\"Correlation between VNQ returns and XLRE returns: {vnq_ret_corr:.3f}\")\n",
    "print(f\"Correlation between IYR returns and XLRE returns: {iyr_ret_corr:.3f}\")\n",
    "\n",
    "print(f\"Using IYR as proxy for XLRE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "TEYxJ4eQsWwW"
   },
   "outputs": [],
   "source": [
    "# first day XLRE existed\n",
    "stitch_date_xlre = '2015-10-08'\n",
    "\n",
    "# proxy data up to (but not including) the stitch date\n",
    "iyr_prices = yf.download(\"IYR\", start='2010-01-01', end=stitch_date_xlre, progress=False)['Close'].squeeze()\n",
    "\n",
    "# real data from the stitch date onwards\n",
    "xlre_prices = yf.download(\"XLRE\", start=stitch_date_xlre, end=end_date, progress=False)['Close'].squeeze()\n",
    "\n",
    "# scaling factor\n",
    "scaling_factor_xlre = xlre_prices.iloc[0] / iyr_prices.iloc[-1]\n",
    "\n",
    "# scaling the entire proxy history\n",
    "scaled_iyr_history = iyr_prices * scaling_factor_xlre\n",
    "\n",
    "# result XLRE\n",
    "continuous_xlre = pd.concat([\n",
    "    scaled_iyr_history,\n",
    "    xlre_prices\n",
    "])\n",
    "\n",
    "df_data['XLRE'] = continuous_xlre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yT6WMbYnX3kP",
    "outputId": "c3e6a3f0-47e1-4a58-fce0-d97ae7b452b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Price Data\n",
      "Shape of Combined Price Data: (3919, 15)\n",
      "Data range: 2010-01-04 00:00:00 to 2025-07-30 00:00:00\n",
      "Missing values: 2161\n",
      "Columns: ['XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLC', 'XLY', 'XLP', 'XLU', 'SPY', 'SHY', '^TNX', 'CL=F']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  XLE       XLF        XLV        XLI        XLB       XLRE  \\\n",
       " Date                                                                          \n",
       " 2010-01-04  35.357689  9.049462  24.296618  21.140421  24.379665  10.800110   \n",
       " 2010-01-05  35.646255  9.215791  24.058332  21.215071  24.458498  10.826041   \n",
       " 2010-01-06  36.073147  9.234272  24.304302  21.259865  24.874134  10.821327   \n",
       " \n",
       "                   XLK  XLC        XLY        XLP        XLU        SPY  \\\n",
       " Date                                                                     \n",
       " 2010-01-04  18.833551  NaN  24.759167  17.607052  18.151886  85.515617   \n",
       " 2010-01-05  18.809265  NaN  24.849947  17.613647  17.935795  85.742012   \n",
       " 2010-01-06  18.598833  NaN  24.882957  17.600449  18.040918  85.802376   \n",
       " \n",
       "                   SHY   ^TNX       CL=F  \n",
       " Date                                     \n",
       " 2010-01-04  67.847778  3.841  81.510002  \n",
       " 2010-01-05  67.929466  3.755  81.769997  \n",
       " 2010-01-06  67.937660  3.808  83.180000  ,\n",
       "                   XLE        XLF         XLV         XLI        XLB  \\\n",
       " Date                                                                  \n",
       " 2025-07-28  88.089996  53.070000  135.289993  154.509995  91.029999   \n",
       " 2025-07-29  88.949997  52.799999  134.429993  152.750000  90.680000   \n",
       " 2025-07-30  87.680000  52.700001  134.190002  152.000000  88.849998   \n",
       " \n",
       "                  XLRE         XLK         XLC         XLY        XLP  \\\n",
       " Date                                                                   \n",
       " 2025-07-28  42.049999  264.079987  107.040001  226.179993  80.660004   \n",
       " 2025-07-29  42.750000  264.089996  106.120003  224.619995  81.190002   \n",
       " 2025-07-30  42.150002  264.679993  106.449997  223.199997  80.470001   \n",
       " \n",
       "                   XLU         SPY        SHY   ^TNX       CL=F  \n",
       " Date                                                            \n",
       " 2025-07-28  83.620003  636.940002  82.540001  4.420  66.709999  \n",
       " 2025-07-29  84.580002  635.260010  82.610001  4.330  69.209999  \n",
       " 2025-07-30  85.209999  634.460022  82.519997  4.376  70.000000  )"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_data_check(df_data, \"Combined Price Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usYjoCuKnbdx",
    "outputId": "ba975c4b-9dfd-4262-d925-ad095ff03dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCOM: available from 2013-10-24\n",
      "VOX: available from 2010-01-04\n",
      "IYZ: available from 2010-01-04\n"
     ]
    }
   ],
   "source": [
    "# checking telecommunication ETFs availability\n",
    "tele_comm = ['FCOM','VOX','IYZ']\n",
    "available_etf = []\n",
    "\n",
    "for etf in tele_comm:\n",
    "  try:\n",
    "    test_data = yf.download(etf,\n",
    "                            start = '2010-01-01',\n",
    "                            end = '2018-06-19',\n",
    "                            progress=False)\n",
    "    if not test_data.empty:\n",
    "      available_etf.append(etf)\n",
    "      print(f\"{etf}: available from {test_data.index.date.min()}\")\n",
    "    else:\n",
    "      print(f\"{etf}: not available\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error downloading {etf}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJQCfpufnr3U",
    "outputId": "29356b05-c82d-4bcb-cfe0-72a1d1c273f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between VOX and XLC: 0.986\n",
      "Correlation between IYZ and XLC: 0.236\n",
      "Correlation between VOX returns and XLC returns: 0.987\n",
      "Correlation between IYZ returns and XLC returns: 0.767\n",
      "Using VOX as proxy for XLC\n"
     ]
    }
   ],
   "source": [
    "# choose between VOX and IYZ by comparing correlation with XLRE\n",
    "vox = yf.download('VOX',\n",
    "                  start = '2018-06-18',\n",
    "                  end = '2025-01-01',\n",
    "                  progress=False)\n",
    "iyz = yf.download('IYZ',\n",
    "                  start = '2018-06-18',\n",
    "                  end = '2025-01-01',\n",
    "                  progress=False)\n",
    "xlc = yf.download('XLC',\n",
    "                  start = '2018-06-18',\n",
    "                  end = '2025-01-01',\n",
    "                  progress=False)\n",
    "\n",
    "vox_close = vox['Close','VOX']\n",
    "iyz_close = iyz['Close','IYZ']\n",
    "xlc = df_data['XLC'].loc['2018-06-18':'2025-01-01'].dropna()\n",
    "\n",
    "vox_corr = vox_close.corr(xlc)\n",
    "iyz_corr = iyz_close.corr(xlc)\n",
    "\n",
    "print(f\"Correlation between VOX and XLC: {vox_corr:.3f}\")\n",
    "print(f\"Correlation between IYZ and XLC: {iyz_corr:.3f}\")\n",
    "\n",
    "vox_return = vox_close.pct_change().dropna()\n",
    "iyz_return = iyz_close.pct_change().dropna()\n",
    "xlc_return = xlc.pct_change().dropna()\n",
    "\n",
    "vox_ret_corr = vox_return.corr(xlc_return)\n",
    "iyz_ret_corr = iyz_return.corr(xlc_return)\n",
    "\n",
    "print(f\"Correlation between VOX returns and XLC returns: {vox_ret_corr:.3f}\")\n",
    "print(f\"Correlation between IYZ returns and XLC returns: {iyz_ret_corr:.3f}\")\n",
    "\n",
    "print(f\"Using VOX as proxy for XLC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "-4xl8hTxrviZ"
   },
   "outputs": [],
   "source": [
    "# scaling proxy etfs to mathc XLC price\n",
    "\n",
    "# first day XLC existed\n",
    "stitch_date_xlc = '2018-06-19'\n",
    "\n",
    "# proxy data up to (but not including) the stitch date\n",
    "vox_prices = yf.download(\"VOX\", start='2010-01-01', end=stitch_date_xlc, progress=False)['Close'].squeeze()\n",
    "\n",
    "# real data from the stitch date onwards\n",
    "xlc_prices = yf.download(\"XLC\", start=stitch_date_xlc, end=end_date, progress=False)['Close'].squeeze()\n",
    "\n",
    "# scaling using the last day of the proxy and first day of the real asset\n",
    "scaling_factor_xlc = xlc_prices.iloc[0] / vox_prices.iloc[-1]\n",
    "\n",
    "# scaling the entire proxy history\n",
    "scaled_vox_history = vox_prices * scaling_factor_xlc\n",
    "\n",
    "# result XLC\n",
    "continuous_xlc = pd.concat([\n",
    "    scaled_vox_history,\n",
    "    xlc_prices\n",
    "])\n",
    "\n",
    "df_data['XLC'] = continuous_xlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhtr4W33nr56",
    "outputId": "ecdc2e9d-0880-4ff8-c0f3-2440785895e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Price Data\n",
      "Shape of Combined Price Data: (3919, 15)\n",
      "Data range: 2010-01-04 00:00:00 to 2025-07-30 00:00:00\n",
      "Missing values: 32\n",
      "Columns: ['XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLC', 'XLY', 'XLP', 'XLU', 'SPY', 'SHY', '^TNX', 'CL=F']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  XLE       XLF        XLV        XLI        XLB       XLRE  \\\n",
       " Date                                                                          \n",
       " 2010-01-04  35.357689  9.049462  24.296618  21.140421  24.379665  10.800110   \n",
       " 2010-01-05  35.646255  9.215791  24.058332  21.215071  24.458498  10.826041   \n",
       " 2010-01-06  36.073147  9.234272  24.304302  21.259865  24.874134  10.821327   \n",
       " \n",
       "                   XLK        XLC        XLY        XLP        XLU        SPY  \\\n",
       " Date                                                                           \n",
       " 2010-01-04  18.833551  24.414905  24.759167  17.607052  18.151886  85.515617   \n",
       " 2010-01-05  18.809265  24.579870  24.849947  17.613647  17.935795  85.742012   \n",
       " 2010-01-06  18.598833  24.190725  24.882957  17.600449  18.040918  85.802376   \n",
       " \n",
       "                   SHY   ^TNX       CL=F  \n",
       " Date                                     \n",
       " 2010-01-04  67.847778  3.841  81.510002  \n",
       " 2010-01-05  67.929466  3.755  81.769997  \n",
       " 2010-01-06  67.937660  3.808  83.180000  ,\n",
       "                   XLE        XLF         XLV         XLI        XLB  \\\n",
       " Date                                                                  \n",
       " 2025-07-28  88.089996  53.070000  135.289993  154.509995  91.029999   \n",
       " 2025-07-29  88.949997  52.799999  134.429993  152.750000  90.680000   \n",
       " 2025-07-30  87.680000  52.700001  134.190002  152.000000  88.849998   \n",
       " \n",
       "                  XLRE         XLK         XLC         XLY        XLP  \\\n",
       " Date                                                                   \n",
       " 2025-07-28  42.049999  264.079987  107.040001  226.179993  80.660004   \n",
       " 2025-07-29  42.750000  264.089996  106.120003  224.619995  81.190002   \n",
       " 2025-07-30  42.150002  264.679993  106.449997  223.199997  80.470001   \n",
       " \n",
       "                   XLU         SPY        SHY   ^TNX       CL=F  \n",
       " Date                                                            \n",
       " 2025-07-28  83.620003  636.940002  82.540001  4.420  66.709999  \n",
       " 2025-07-29  84.580002  635.260010  82.610001  4.330  69.209999  \n",
       " 2025-07-30  85.209999  634.460022  82.519997  4.376  70.000000  )"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_data_check(df_data, \"Combined Price Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5ZLfpPvkM-s",
    "outputId": "5e60e910-e575-41e5-e515-3695cbf8cd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Price Data\n",
      "Shape of Combined Price Data: (3919, 16)\n",
      "Data range: 2010-01-04 00:00:00 to 2025-07-30 00:00:00\n",
      "Missing values: 36\n",
      "Columns: ['XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLC', 'XLY', 'XLP', 'XLU', 'SPY', 'SHY', '^TNX', 'CL=F', 'HY_SPREAD']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  XLE       XLF        XLV        XLI        XLB       XLRE  \\\n",
       " Date                                                                          \n",
       " 2010-01-04  35.357689  9.049462  24.296618  21.140421  24.379665  10.800110   \n",
       " 2010-01-05  35.646255  9.215791  24.058332  21.215071  24.458498  10.826041   \n",
       " 2010-01-06  36.073147  9.234272  24.304302  21.259865  24.874134  10.821327   \n",
       " \n",
       "                   XLK        XLC        XLY        XLP        XLU        SPY  \\\n",
       " Date                                                                           \n",
       " 2010-01-04  18.833551  24.414905  24.759167  17.607052  18.151886  85.515617   \n",
       " 2010-01-05  18.809265  24.579870  24.849947  17.613647  17.935795  85.742012   \n",
       " 2010-01-06  18.598833  24.190725  24.882957  17.600449  18.040918  85.802376   \n",
       " \n",
       "                   SHY   ^TNX       CL=F  HY_SPREAD  \n",
       " Date                                                \n",
       " 2010-01-04  67.847778  3.841  81.510002       6.34  \n",
       " 2010-01-05  67.929466  3.755  81.769997       6.30  \n",
       " 2010-01-06  67.937660  3.808  83.180000       6.17  ,\n",
       "                   XLE        XLF         XLV         XLI        XLB  \\\n",
       " Date                                                                  \n",
       " 2025-07-28  88.089996  53.070000  135.289993  154.509995  91.029999   \n",
       " 2025-07-29  88.949997  52.799999  134.429993  152.750000  90.680000   \n",
       " 2025-07-30  87.680000  52.700001  134.190002  152.000000  88.849998   \n",
       " \n",
       "                  XLRE         XLK         XLC         XLY        XLP  \\\n",
       " Date                                                                   \n",
       " 2025-07-28  42.049999  264.079987  107.040001  226.179993  80.660004   \n",
       " 2025-07-29  42.750000  264.089996  106.120003  224.619995  81.190002   \n",
       " 2025-07-30  42.150002  264.679993  106.449997  223.199997  80.470001   \n",
       " \n",
       "                   XLU         SPY        SHY   ^TNX       CL=F  HY_SPREAD  \n",
       " Date                                                                       \n",
       " 2025-07-28  83.620003  636.940002  82.540001  4.420  66.709999       2.82  \n",
       " 2025-07-29  84.580002  635.260010  82.610001  4.330  69.209999        NaN  \n",
       " 2025-07-30  85.209999  634.460022  82.519997  4.376  70.000000        NaN  )"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high yield credit spread (risk premium)\n",
    "# difference between safer bonds and junk bonds\n",
    "fred_data = pd.read_csv('BAMLH0A0HYM2.csv')\n",
    "fred_data['observation_date'] = pd.to_datetime(fred_data['observation_date'])\n",
    "fred_data.set_index('observation_date', inplace=True)\n",
    "fred_data.rename(columns={'BAMLH0A0HYM2': 'HY_SPREAD'}, inplace=True)\n",
    "df_data = df_data.merge(fred_data, left_index=True, right_index=True, how='left')\n",
    "\n",
    "quick_data_check(df_data, \"Combined Price Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "S8XnsVXC3xbQ"
   },
   "outputs": [],
   "source": [
    "df_data.to_csv('df_sector_rotation_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRsyFcgTfFnW"
   },
   "source": [
    "## Part 2-1\n",
    "\n",
    "### Feature set engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtxefRendxPA",
    "outputId": "b427269c-b56e-4b9c-e2dc-de75625bc354"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/df_sector_rotation_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load and check duplicates\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/Colab Notebooks/df_sector_rotation_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique dates: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/df_sector_rotation_data.csv'"
     ]
    }
   ],
   "source": [
    "# load and check duplicates\n",
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/df_sector_rotation_data.csv')\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Unique dates: {df['Date'].nunique()}\")\n",
    "\n",
    "duplicate_dates = df[df['Date'].duplicated(keep=False)]\n",
    "if not duplicate_dates.empty:\n",
    "    print(duplicate_dates[['Date']].sort_values('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etqPgVRymUiH"
   },
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "sectors = ['XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE',\n",
    "           'XLK', 'XLC', 'XLY', 'XLP', 'XLU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BS2bz7pmmq4"
   },
   "outputs": [],
   "source": [
    "def create_feature_a(df, sectors):\n",
    "  features_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "  for sector in sectors:\n",
    "    prices = df[sector]\n",
    "    returns = prices.pct_change()\n",
    "    # return 63 days (3 month momentum)\n",
    "    features_df[f'{sector}_return_63d'] = prices.pct_change(63)\n",
    "    # return 252 days (1 year trend)\n",
    "    features_df[f'{sector}_return_252d'] = prices.pct_change(252)\n",
    "    # volatility 63 days (3 month volatility)\n",
    "    features_df[f'{sector}_volatility_63d'] = returns.rolling(63).std() * np.sqrt(252)\n",
    "\n",
    "    rolling_return = returns.rolling(63).mean()*252\n",
    "    rolling_vol = returns.rolling(63).std()*np.sqrt(252)\n",
    "    # sharpe 63 days (risk adjusted return)\n",
    "    features_df[f'{sector}_sharpe_63d'] = rolling_return / rolling_vol\n",
    "\n",
    "  # ranking by return 63 days (cross sectional relative strength)\n",
    "  return_63d_cols = [col for col in features_df.columns if 'return_63d' in col]\n",
    "  rank_df = features_df[return_63d_cols].rank(axis=1, method='min')\n",
    "  for i, sector in enumerate(sectors):\n",
    "    if f'{sector}_return_63d' in rank_df.columns:\n",
    "      features_df[f'{sector}_rank_return_63d'] = rank_df[f'{sector}_return_63d']\n",
    "\n",
    "  spy_200ma = df['SPY'].rolling(200).mean()\n",
    "  # regime filter (if spy was above 200 day ma)\n",
    "  features_df['spy_above_200ma'] = (df['SPY'] > spy_200ma).astype(int)\n",
    "  # energy sector specifiec feature (oil price momentum)\n",
    "  features_df['oil_price_momentum_63d'] = df['CL=F'].pct_change(63)\n",
    "  # interest rate level\n",
    "  features_df['treasury_10y_level'] = df['^TNX']\n",
    "  # high yield credit spread (credit risk measure)\n",
    "  features_df['hy_credit_spread'] = df['HY_SPREAD']\n",
    "\n",
    "  return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbQ9F6ne2OHl",
    "outputId": "68c30349-4b9a-485f-9cd7-2ea8086d0534"
   },
   "outputs": [],
   "source": [
    "features_a = create_feature_a(df, sectors)\n",
    "\n",
    "quick_data_check(features_a, \"Feature Set A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOSRClJb2V-Y"
   },
   "outputs": [],
   "source": [
    "features_a.to_csv('/content/drive/My Drive/Colab Notebooks/features_set_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ng2HZrua3dWK"
   },
   "outputs": [],
   "source": [
    "features_b = features_a.copy()\n",
    "features_b['treasury_10y_1m_change'] = df['^TNX'].pct_change(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-dbb7PW5-QK",
    "outputId": "48d67ee5-8b9d-4973-fc9c-c02f8083fa2f"
   },
   "outputs": [],
   "source": [
    "quick_data_check(features_b, \"Feature Set B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paE8kM1M5od3"
   },
   "outputs": [],
   "source": [
    "features_b.to_csv('/content/drive/My Drive/Colab Notebooks/features_set_b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqYU8JEdMOSn"
   },
   "source": [
    "## Part 2-2\n",
    "\n",
    "### Target engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sJHNPIv5r57"
   },
   "outputs": [],
   "source": [
    "# 21 day forward log returns for each sector\n",
    "def create_forward_return(df, sectors):\n",
    "  target_df = pd.DataFrame(index=df.index)\n",
    "  for sector in sectors:\n",
    "    if sector in df.columns:\n",
    "      # 21 day forward log returns\n",
    "      future_price = df[sector].shift(-21)\n",
    "      current_price = df[sector]\n",
    "      # log returns\n",
    "      target_df[f'{sector}_return_21d_forward'] = np.log(future_price / current_price)\n",
    "\n",
    "  return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gI0sRNTQNTsi",
    "outputId": "12e7cce3-d10c-4004-ecfb-1fef7ac31dbb"
   },
   "outputs": [],
   "source": [
    "targets = create_forward_return(df, sectors)\n",
    "\n",
    "quick_data_check(targets, \"Target Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKIhqH65NUEz"
   },
   "outputs": [],
   "source": [
    "targets.to_csv('/content/drive/My Drive/Colab Notebooks/target_21d_forward.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHVGNosbWPPN"
   },
   "source": [
    "## Part 3-1\n",
    "\n",
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6euYA-saVEG",
    "outputId": "92052b8e-d2e6-475a-ffa0-9399fcb86dcc"
   },
   "outputs": [],
   "source": [
    "# merging features and targets\n",
    "features_a['Date'] = pd.to_datetime(features_a.index)\n",
    "features_a.set_index('Date', inplace=True)\n",
    "features_b['Date'] = pd.to_datetime(features_b.index)\n",
    "features_b.set_index('Date', inplace=True)\n",
    "targets['Date'] = pd.to_datetime(targets.index)\n",
    "targets.set_index('Date', inplace=True)\n",
    "\n",
    "data_a = features_a.merge(targets, left_index=True, right_index=True, how='inner')\n",
    "data_b = features_b.merge(targets, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "print(f\"Features A shape: {data_a.shape}\")\n",
    "print(f\"Features B shape: {data_b.shape}\")\n",
    "print(f\"Data A shape: {data_a.shape}\")\n",
    "print(f\"Data B shape: {data_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAb26sdfiDYR"
   },
   "outputs": [],
   "source": [
    "data_a.to_csv('/content/drive/My Drive/Colab Notebooks/modeling_data_a.csv')\n",
    "data_b.to_csv('/content/drive/My Drive/Colab Notebooks/modeling_data_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yq600w0mLXjc",
    "outputId": "da015003-87e2-440d-8dd6-e6b7eca492d3"
   },
   "outputs": [],
   "source": [
    "# checking infinite values\n",
    "numeric_cols = data_a.select_dtypes(include=[np.number]).columns\n",
    "inf_ct = []\n",
    "for col in numeric_cols:\n",
    "  if data_a[col].isin([np.inf, -np.inf]).any():\n",
    "    inf_ct.append(col)\n",
    "print(f\"Infinite values: {inf_ct}\")\n",
    "if not inf_ct:\n",
    "  print(\"No infinite values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82MkACWYLXl9",
    "outputId": "e091a24c-173d-4bc0-e27b-728e2b0d6e2a"
   },
   "outputs": [],
   "source": [
    "# checking outliers\n",
    "for col in numeric_cols:\n",
    "  q1 = data_a[col].quantile(.01)\n",
    "  q99 = data_a[col].quantile(.99)\n",
    "  outlier_low = (data_a[col] < q1).sum()\n",
    "  outlier_high = (data_a[col] > q99).sum()\n",
    "  total_outliers = outlier_low + outlier_high\n",
    "  if total_outliers > 0:\n",
    "    print(f\"{col}: {total_outliers} outliers\")\n",
    "  else:\n",
    "    print(f\"{col}: no outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o95Ch3VclNd9",
    "outputId": "32ce44a3-99ea-4779-d1aa-cd37787642de"
   },
   "outputs": [],
   "source": [
    "q1 = data_a['XLE_return_63d'].quantile(.01)\n",
    "q99 = data_a['XLE_return_63d'].quantile(.99)\n",
    "print(f\"Max loss: {q1}\")\n",
    "print(f\"Max gain: {q99}\")\n",
    "\n",
    "outlier_mask = (data_a['XLE_return_63d'] < q1) | (data_a['XLE_return_63d'] > q99)\n",
    "outliers_dates = data_a[outlier_mask].index\n",
    "print(f\"Outliers dates: \\n{outliers_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FshGn2N4pAR-"
   },
   "source": [
    "- Outlier dates are valid ones.\n",
    "- In March-June 2020, market experienced COVID crash and recovery\n",
    "- In early 2021, market volatility went up with GameStop and meme stock boom\n",
    "- In March-April 2022, Russia invaded Ukraine provoking inflation fears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjYBjIKPm8nT",
    "outputId": "3d5c211b-4c0f-494f-b8bd-287aa2d3647c"
   },
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_ct = data_a.isnull().sum().sort_values(ascending=False)\n",
    "print(f\"Missing values: \\n{missing_ct}\\n\")\n",
    "missing_pct = missing_ct / len(data_a) * 100\n",
    "print(f\"Missing values percentage: \\n{missing_pct}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2B19Vr9cm9Cr",
    "outputId": "243135a2-2ce4-49f4-b07e-e864c752464c"
   },
   "outputs": [],
   "source": [
    "total_missing = missing_ct.sum()\n",
    "print(f\"Total missing values: {total_missing}\")\n",
    "print(f\"Total cells in dataset: {len(data_a) * len(data_a.columns)}\")\n",
    "print(f\"Percentage of missing values: {total_missing / (len(data_a) * len(data_a.columns)) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CsRQia_xSzN",
    "outputId": "cb582a6e-5d31-437a-9c1d-d67abec52b2c"
   },
   "outputs": [],
   "source": [
    "# forward filling missing values up to 5 days\n",
    "# assuming the last known price persists until new information arrives\n",
    "data_a_filled = data_a.fillna(method='ffill', limit=5)\n",
    "print(f\"Missing values before forward-fill: {total_missing}\")\n",
    "print(f\"Missing values after forward-fill: {data_a_filled.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liQMJsH6tt2P",
    "outputId": "01588585-5de3-4b16-f0ad-1ba487f4b3ad"
   },
   "outputs": [],
   "source": [
    "df_clean = data_a_filled.dropna()\n",
    "print(f\"Before cleaning: {data_a_filled.shape}\")\n",
    "print(f\"After cleaning: {df_clean.shape}\")\n",
    "print(f\"Data range: {df_clean.index.date.min()} to {df_clean.index.date.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uY6daDTuuiP"
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('/content/drive/My Drive/Colab Notebooks/modeling_data_a_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbFTjzR38cKn"
   },
   "source": [
    "## Part 3-2\n",
    "\n",
    "### Timeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RekXnyo98lJL"
   },
   "source": [
    "A strict T-2 timeline will be used to prevent look-ahead bias.\n",
    "- Predictions are generated two days before month end and trades are executed on the last trading day of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wg9D94fS8j17",
    "outputId": "b4f6bea2-c14d-4518-8a59-def8f8a33d7a"
   },
   "outputs": [],
   "source": [
    "month_ends = df_clean.resample('BM').last().index\n",
    "t2_dates = month_ends - pd.tseries.offsets.BDay(2)\n",
    "df_t2 = df_clean.loc[df_clean.index.isin(t2_dates)]\n",
    "\n",
    "print(f\"Original datast: {len(df_clean)} observations\")\n",
    "print(f\"T-2 dataset: {len(df_t2)} observations\")\n",
    "print(f\"Date range: {df_t2.index.date.min()} to {df_t2.index.date.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJHJ45dflNxa"
   },
   "outputs": [],
   "source": [
    "df_t2.to_csv('/content/drive/My Drive/Colab Notebooks/modeling_data_a_t2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iTjHYL896OY"
   },
   "source": [
    "## Part 3-3\n",
    "\n",
    "### Walk forward validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EigKYMTF-dB_"
   },
   "source": [
    "- The model will be tested using an expanding window, retrained monthly, with a minimum initial training period of 36 months.\n",
    "- The model will be always tested on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pwL_CFk9H2o",
    "outputId": "22f48373-86c1-4347-da32-9c111b47deb7"
   },
   "outputs": [],
   "source": [
    "# minimum training window = 36 months\n",
    "min_train_month = 36\n",
    "start_idx = min_train_month - 1\n",
    "\n",
    "# walk forward validation\n",
    "results = []\n",
    "for i in range(start_idx, len(df_t2)):\n",
    "  # expanding window from start to current by 1 month\n",
    "  train_data = df_t2.iloc[:i+1]\n",
    "\n",
    "  # next month\n",
    "  if i + 1 < len(df_t2):\n",
    "    test_data = df_t2.iloc[i+1:i+2]\n",
    "    results.append({\n",
    "        'train_end': train_data.index.date[-1],\n",
    "        'test_date': test_data.index.date[0],\n",
    "        'train_size': len(train_data)\n",
    "    })\n",
    "\n",
    "print(f\"Total prediction: {len(results)}\")\n",
    "print(f\"First prediction: {results[0]['test_date']}\")\n",
    "print(f\"Last prediction: {results[-1]['test_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ufvyT_ZAZ8o"
   },
   "source": [
    "- 1st prediction: Train on 36 months (2011-2014), predict Feb 2014\n",
    "- 2nd prediction: Train on 37 months (2011-2014), predict Mar 2014\n",
    "- continues as long as data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIiPd7NF_9Yt"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('/content/drive/My Drive/Colab Notebooks/walk_forward_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbpaJIKHBPRa"
   },
   "source": [
    "## Part 4-1\n",
    "\n",
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sgGN7MqBUM4",
    "outputId": "9f0433b5-13ef-4c3a-fc05-59db28946770"
   },
   "outputs": [],
   "source": [
    "# random forest\n",
    "# separating target and features\n",
    "feature_cols = [col for col in df_t2.columns if not col.endswith('_return_21d_forward')]\n",
    "target_cols = [col for col in df_t2.columns if col.endswith('_return_21d_forward')]\n",
    "\n",
    "rf_mod = RandomForestRegressor(n_estimators=100,\n",
    "                               random_state=42,\n",
    "                               max_depth=3)\n",
    "scaler = StandardScaler()\n",
    "rf_pred = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "  # training data\n",
    "  train_data = df_t2.iloc[:start_idx + i + 1]\n",
    "  X_train = scaler.fit_transform(train_data[feature_cols])\n",
    "  y_train = train_data[target_cols].values\n",
    "\n",
    "  # testing data\n",
    "  test_data = df_t2.iloc[start_idx + i + 1:start_idx + i + 2]\n",
    "  X_test = scaler.transform(test_data[feature_cols])\n",
    "\n",
    "  # predict\n",
    "  rf_mod.fit(X_train, y_train)\n",
    "  pred = rf_mod.predict(X_test)\n",
    "\n",
    "  # results\n",
    "  sector_dict = dict(zip([col.replace('_return_21d_forward','') for col in target_cols], pred[0]))\n",
    "  rf_pred.append({'date': result['test_date'], **sector_dict})\n",
    "\n",
    "print(f\"Total predictions: {len(rf_pred)}\")\n",
    "print(f\"First prediction: {rf_pred[0]['date']}\")\n",
    "print(f\"Last prediction: {rf_pred[-1]['date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YW-4nU72MiRS",
    "outputId": "c34b8f9a-1cc2-4acf-e36d-e08edc908930"
   },
   "outputs": [],
   "source": [
    "# rankings\n",
    "rf_pred_df = pd.DataFrame(rf_pred)\n",
    "rf_pred_df.set_index('date', inplace=True)\n",
    "\n",
    "rf_rankings = rf_pred_df.rank(axis=1, ascending=False)\n",
    "\n",
    "print(\"Sample predictions:\")\n",
    "print(rf_pred_df.head(3))\n",
    "print(\"\\nSample rankings:\")\n",
    "print(rf_rankings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwuVg6OQNEKG",
    "outputId": "b795e7b5-2f70-4b58-83d3-6334ae73f87a"
   },
   "outputs": [],
   "source": [
    "# actual returns\n",
    "actual_returns_df = df_t2[target_cols].copy()\n",
    "actual_returns_df.columns = [col.replace('_return_21d_forward','') for col in target_cols]\n",
    "actual_returns_df = actual_returns_df.loc[rf_pred_df.index]\n",
    "actual_returns_rankings = actual_returns_df.rank(axis=1, ascending=False)\n",
    "\n",
    "print(\"Actual returns:\")\n",
    "print(actual_returns_df.head(3))\n",
    "print(\"\\nActual rankings:\")\n",
    "print(actual_returns_rankings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rH4xGAO6OVQT",
    "outputId": "73ec45a8-fb0f-453b-ab56-e1100e7a7a4e"
   },
   "outputs": [],
   "source": [
    "rank_corr = rf_rankings.corrwith(actual_returns_rankings, axis=1).mean()\n",
    "print(f\"Rank correlation: {rank_corr.mean()*100:.3f}\") # no predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UatfyQjEOpJv",
    "outputId": "2695ab44-f400-43b5-c233-65223c32cd41"
   },
   "outputs": [],
   "source": [
    "# random forest accuracy\n",
    "# % of time top 3 predicted match actual top 3\n",
    "def calculate_top3_accuracy(pred_rankings, actual_rankings):\n",
    "  top3_matches = 0\n",
    "  total_predictions = len(pred_rankings)\n",
    "  for i in range(len(rf_rankings)):\n",
    "    # top 3 predicted sectors\n",
    "    pred_top3 = set(rf_rankings.iloc[i].nsmallest(3).index)\n",
    "    # top 3 actual sectors\n",
    "    actual_top3 = set(actual_returns_rankings.iloc[i].nsmallest(3).index)\n",
    "\n",
    "    overlap = len(set(pred_top3) & set(actual_top3))\n",
    "    top3_matches += overlap / 3\n",
    "\n",
    "  return top3_matches / total_predictions\n",
    "\n",
    "rf_accuracy = calculate_top3_accuracy(rf_rankings, actual_returns_rankings)\n",
    "print(f\"Top 3 accuracy: {rf_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-JSWU9bsA_5",
    "outputId": "011873a1-8c66-45bd-f54f-e441ceb887e3"
   },
   "outputs": [],
   "source": [
    "# direction accuracy for random forest\n",
    "rf_direction_correct = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i in range(len(rf_pred_df)):\n",
    "  for sector in rf_pred_df.columns:\n",
    "    predicted_return = rf_pred_df.iloc[i][sector]\n",
    "    actual_return = actual_returns_df.iloc[i][sector]\n",
    "\n",
    "    if (predicted_return > 0 and actual_return > 0) or (predicted_return < 0 and actual_return < 0):\n",
    "      rf_direction_correct += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "rf_direction_accuracy = rf_direction_correct / total_predictions\n",
    "print(f\"Direction accuracy: {rf_direction_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vd9lrqj_Vn8w"
   },
   "outputs": [],
   "source": [
    "# feature importance check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svlyww6zVwvf"
   },
   "source": [
    "## Part 4-2\n",
    "\n",
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2SOZbDzIsNT",
    "outputId": "80686a5b-b682-4ade-e644-f8119c8290c4"
   },
   "outputs": [],
   "source": [
    "# elastic net\n",
    "elnet_mod = ElasticNet(alpha=0.1,\n",
    "                       l1_ratio=0.5,\n",
    "                       random_state=42)\n",
    "scaler = StandardScaler()\n",
    "elnet_pred = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "  # training data\n",
    "  train_data = df_t2.iloc[:start_idx + i + 1]\n",
    "  X_train = scaler.fit_transform(train_data[feature_cols])\n",
    "  y_train = train_data[target_cols].values\n",
    "\n",
    "  # testing data\n",
    "  test_data = df_t2.iloc[start_idx + i + 1:start_idx + i + 2]\n",
    "  X_test = scaler.transform(test_data[feature_cols])\n",
    "\n",
    "  # predict\n",
    "  elnet_mod.fit(X_train, y_train)\n",
    "  pred = elnet_mod.predict(X_test)[0]\n",
    "\n",
    "  # results\n",
    "  sector_dict = dict(zip([col.replace('_return_21d_forward','') for col in target_cols], pred))\n",
    "  elnet_pred.append({'date': result['test_date'], **sector_dict})\n",
    "\n",
    "print(f\"Elastic net total predictions: {len(elnet_pred)}\")\n",
    "print(f\"First prediction: {elnet_pred[0]['date']}\")\n",
    "print(f\"Last prediction: {elnet_pred[-1]['date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QECtv2eIsPp",
    "outputId": "84ad09c0-cc47-4df6-b66f-c6a04e7ed9d6"
   },
   "outputs": [],
   "source": [
    "# rankings\n",
    "elnet_pred_df = pd.DataFrame(elnet_pred)\n",
    "elnet_pred_df.set_index('date', inplace=True)\n",
    "elnet_rankings = elnet_pred_df.rank(axis=1, ascending=False)\n",
    "\n",
    "print(\"Sample predictions:\")\n",
    "print(elnet_pred_df.head(3))\n",
    "print(\"\\nActual returns:\")\n",
    "print(actual_returns_df.head(3))\n",
    "print(\"\\nSample rankings:\")\n",
    "print(elnet_rankings.head(3))\n",
    "print(\"\\nActual rankings:\")\n",
    "print(actual_returns_rankings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_R3lXBHUIsR5",
    "outputId": "ea1c4370-ad95-435f-bfc2-275d3cc29088"
   },
   "outputs": [],
   "source": [
    "# elastic net accuracy\n",
    "total_correct = 0\n",
    "total_possible = len(elnet_rankings) * 3\n",
    "\n",
    "for i in range(len(elnet_rankings)):\n",
    "  pred_top3 = set(elnet_rankings.iloc[i].nsmallest(3).index)\n",
    "  actual_top3 = set(actual_returns_rankings.iloc[i].nsmallest(3).index)\n",
    "  total_correct += len(pred_top3 & actual_top3)\n",
    "\n",
    "elnet_accuracy = total_correct / total_possible\n",
    "print(f\"Top 3 accuracy: {elnet_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH2ZbkEupUBV",
    "outputId": "52fcc7da-92fc-4513-c9bc-e4011290b042"
   },
   "outputs": [],
   "source": [
    "# direction accuracy for elastic net\n",
    "elnet_direction_correct = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i in range(len(elnet_pred_df)):\n",
    "  for sector in elnet_pred_df.columns:\n",
    "    predicted_return = elnet_pred_df.iloc[i][sector]\n",
    "    actual_return = actual_returns_df.iloc[i][sector]\n",
    "\n",
    "    if (predicted_return > 0 and actual_return > 0) or (predicted_return < 0 and actual_return < 0):\n",
    "      elnet_direction_correct += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "elnet_direction_correct = elnet_direction_correct / total_predictions\n",
    "print(f\"Direction accuracy: {elnet_direction_correct:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-kZtiEsQs1e"
   },
   "source": [
    "## Part 4-3\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AouCb9_9SwFW",
    "outputId": "3bf937a4-62b2-4723-9649-bfd90b56585a"
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "# random guessing top 3\n",
    "import random\n",
    "sim_accuracy = []\n",
    "nrep = 1000\n",
    "\n",
    "for i in range(nrep):\n",
    "  total_mathes = 0\n",
    "  for j in range(len(rf_rankings)):\n",
    "    random_top3 = set(random.sample(rf_rankings.columns.tolist(), 3))\n",
    "    actual_top3 = set(actual_returns_rankings.iloc[j].nsmallest(3).index)\n",
    "\n",
    "    total_mathes += len(random_top3 & actual_top3)\n",
    "\n",
    "  accuracy = total_mathes / (len(rf_rankings) *3)\n",
    "  sim_accuracy.append(accuracy)\n",
    "\n",
    "baseline = np.mean(sim_accuracy)\n",
    "print(f\"Baseline accuracy: {baseline:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGW7K8RSua8v",
    "outputId": "9c9e83f6-40b6-45fb-ea16-64faef01db35"
   },
   "outputs": [],
   "source": [
    "# random guessing direction\n",
    "sim_direction_accuracy = []\n",
    "nrep = 1000\n",
    "\n",
    "for i in range(nrep):\n",
    "  total_correct = 0\n",
    "  total_predictions = 0\n",
    "  for j in range(len(rf_rankings)):\n",
    "    for sector in rf_rankings.columns:\n",
    "      random_direction = random.choice([-1, 1])\n",
    "      actual_return = actual_returns_df.iloc[j][sector]\n",
    "      actual_direction = 1 if actual_return > 0 else -1\n",
    "\n",
    "      if random_direction == actual_direction:\n",
    "        total_correct += 1\n",
    "      total_predictions += 1\n",
    "\n",
    "  direction_accuracy = total_correct / total_predictions\n",
    "  sim_direction_accuracy.append(direction_accuracy)\n",
    "\n",
    "baseline_direction_accuracy = np.mean(sim_direction_accuracy)\n",
    "print(f\"Baseline direction accuracy: {baseline_direction_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDy_JX7T3fIW",
    "outputId": "7c661ca8-4525-4b69-cc37-4b97598e091b"
   },
   "outputs": [],
   "source": [
    "# simple momentum baseline\n",
    "# 63-day (3 month) return\n",
    "momentum_baseline = [col for col in df_t2.columns if '_rank_return_63d' in col and not col.endswith('_forward')]\n",
    "\n",
    "if momentum_baseline:\n",
    "  momentum_data = df_t2[momentum_baseline].loc[rf_pred_df.index]\n",
    "  momentum_rankings = momentum_data.rank(axis=1, ascending=False)\n",
    "  momentum_accuracy = calculate_top3_accuracy(momentum_rankings, actual_returns_rankings)\n",
    "  print(f\"Momentum accuracy: {momentum_accuracy:.1%}\")\n",
    "else:\n",
    "  print(\"No momentum data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqbypCeA3fLD",
    "outputId": "250f5f7f-55e5-4b87-c01e-d27f0cc7b86f"
   },
   "outputs": [],
   "source": [
    "# momentum direction baseline\n",
    "momentum_direction_baseline = [col for col in df_t2.columns if '_return_63d' in col and 'rank' not in col]\n",
    "momentum_data = df_t2[momentum_direction_baseline].loc[rf_pred_df.index]\n",
    "\n",
    "momentum_direction_correct = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i in range(len(momentum_data)):\n",
    "  for col in momentum_direction_baseline:\n",
    "    sector = col.replace('_return_63d', '')\n",
    "\n",
    "    momentum_return = momentum_data.iloc[i][col]\n",
    "    predicted_direction = 1 if momentum_return > 0 else -1\n",
    "\n",
    "    actual_return = actual_returns_df.iloc[i][sector]\n",
    "    actual_direction = 1 if actual_return > 0 else -1\n",
    "\n",
    "    if predicted_direction == actual_direction:\n",
    "      momentum_direction_correct += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "momentum_direction_accuracy = momentum_direction_correct / total_predictions\n",
    "print(f\"Momentum direction accuracy: {momentum_direction_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Az4m_jepUDp",
    "outputId": "42bf1962-24ca-4731-914b-0cb6ae673d7b"
   },
   "outputs": [],
   "source": [
    "# result table\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Baseline', 'Momentum Baseline',\n",
    "              'Random Forest', 'Elastic Net'],\n",
    "    'Top 3 ETFs Accuracy': [baseline, momentum_accuracy,\n",
    "                       rf_accuracy, elnet_accuracy],\n",
    "    'Direction Accuracy': [baseline_direction_accuracy,\n",
    "                           momentum_direction_accuracy,\n",
    "                           rf_direction_accuracy,\n",
    "                           elnet_direction_correct,]\n",
    "})\n",
    "\n",
    "results['Top 3 ETFs Accuracy'] = results[\n",
    "    'Top 3 ETFs Accuracy'].apply(lambda x: f\"{x*100:.1f}%\")\n",
    "\n",
    "\n",
    "results['Direction Accuracy'] = results[\n",
    "    'Direction Accuracy'].apply(lambda x: f\"{x*100:.1f}%\")\n",
    "\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "1v5-tPIk93Q_",
    "outputId": "35fb8f6e-80a0-434c-a622-5e9b8f37aa51"
   },
   "outputs": [],
   "source": [
    "# top 3 accuracy comparison\n",
    "models = ['Random\\nBaseline', 'Momentum\\nBaseline', 'Random\\nForest', 'Elastic\\nNet']\n",
    "top3_scores = [baseline, momentum_accuracy, rf_accuracy, elnet_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, top3_scores, width=0.6,\n",
    "               color=['lightgray', 'lightblue', 'skyblue', 'steelblue'])\n",
    "plt.axhline(y=baseline, color='black', linestyle=':',\n",
    "            label=f'Baseline: {baseline:.1%}')\n",
    "plt.ylabel('Top-3 Accuracy (%)')\n",
    "plt.title('Ranking Top-3 ETFs Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "V_dxxmYz_jJc",
    "outputId": "c4032c24-b1ee-44d7-9bb4-f3c16e1f3d8b"
   },
   "outputs": [],
   "source": [
    "# direction accuracy comparison\n",
    "direction_scores = [baseline_direction_accuracy, momentum_direction_accuracy,\n",
    "                    rf_direction_accuracy, elnet_direction_correct]\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, direction_scores, width=0.6,\n",
    "               color=['lightgray', 'lightblue', 'skyblue', 'steelblue'])\n",
    "plt.axhline(y=baseline_direction_accuracy, color='black', linestyle=':',\n",
    "            label=f'Baseline: {baseline_direction_accuracy:.1%}')\n",
    "plt.ylabel('Direction Accuracy (%)')\n",
    "plt.title('Direction Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLBfb8I2hEY4"
   },
   "source": [
    "Result analysis\n",
    "\n",
    "Need result analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UESHN2tQhxB"
   },
   "source": [
    "## Part 5-1\n",
    "\n",
    "### Random forest analysis (feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc_vrnUnQ2ix",
    "outputId": "47bfbf0c-b035-4d6c-b66f-659d8e920fc9"
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "# random forest\n",
    "rf_feature_importance = rf_mod.feature_importances_\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"Random Forest top 30 Feature Importance:\")\n",
    "print(rf_importance_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "Ec65eCOJWOGa",
    "outputId": "cf5a56e2-6ae5-4ca7-8b5d-448468520255"
   },
   "outputs": [],
   "source": [
    "# random forest feature importance plot\n",
    "top5_features = rf_importance_df.head(5)\n",
    "macro_features = rf_importance_df[rf_importance_df['Feature'].isin([\n",
    "    'hy_credit_spread','oil_price_momentum_63d',\n",
    "    'treasury_10y_level','spy_above_200ma'\n",
    "])]\n",
    "\n",
    "plot_data = pd.concat([top5_features, macro_features]).drop_duplicates()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(plot_data['Feature'], plot_data['Importance']*100,\n",
    "         color=['steelblue']*5 + ['coral']*len(macro_features))\n",
    "plt.xlabel('Feature Importance (%)')\n",
    "plt.title('Random Forest Feature Importance: Top Features vs Macro Variables')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMdzrehD-gsY"
   },
   "source": [
    "- extreme concentration on single sector, XLE, accouts more than 30% of the model's predictive power\n",
    "- model is basing a huge portion of its decision on 11 sectors based on behavior of one or two sectors (XLE, XLF)\n",
    "- macro features show weaker importance compared to momentum features\n",
    "- regime macro feature based on SPY is completely ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEjCy2w-qgpW",
    "outputId": "031ade26-4792-482e-ef04-9961d8cb7ab7"
   },
   "outputs": [],
   "source": [
    "# check SPY above 200MA counts\n",
    "spy_regime = df_t2['spy_above_200ma'].value_counts()\n",
    "print(spy_regime)\n",
    "print(f\"Percentage above 200MA: {spy_regime[1]/len(df_t2):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "voWaOqaqAFHw",
    "outputId": "eb3ccc23-5b30-4d33-b67b-ec7e13d7230e"
   },
   "outputs": [],
   "source": [
    "# SPY feature barplot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar([1,0], spy_regime.values, color=['steelblue','lightgray'], width=.5,\n",
    "        label=[f'Bull: 82.2%', f'Bear: 17.8%'])\n",
    "plt.xlabel('SPY above 200-Day MA')\n",
    "plt.ylabel('Number of Months')\n",
    "plt.title('Market Regime Distribution (Bull vs Bear)')\n",
    "plt.xticks([1,0], ['Above 200MA\\n(Bull)','Below 200MA\\n(Bear)'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZmeKy93ra5W"
   },
   "source": [
    "- 82.2% of the time SPY was above 200MA\n",
    "- Only 30 months of bear market\n",
    "- 18% bear market period is not enough to create meaningful patters for random forest\n",
    "- Model learned everything goes up which made regime feature useless because it was dominated by bull market\n",
    "- This leads to suspicion that direction accuracy coming from bull market persistence, and not from modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71MYM43LSyDY"
   },
   "source": [
    "## Part 5-2\n",
    "\n",
    "### Elastic net analysis (feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLAlbVbwRk26",
    "outputId": "40f00d4b-50e8-493a-d5f6-1cdbf563f758"
   },
   "outputs": [],
   "source": [
    "# elastic net\n",
    "elnet_feature_importance = np.abs(elnet_mod.coef_).mean(axis=0)\n",
    "elnet_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': elnet_feature_importance\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(f\"Elastic Net top 10 Feature Importance:\")\n",
    "print(elnet_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "C2GsBYcJR_oN",
    "outputId": "624b395c-0ade-46b1-b034-a74e58a071b0"
   },
   "outputs": [],
   "source": [
    "# elastic net feature importance plot\n",
    "# blank plot\n",
    "top5_features = elnet_importance_df.head(5)\n",
    "macro_features = elnet_importance_df[elnet_importance_df['Feature'].isin([\n",
    "    'hy_credit_spread','oil_price_momentum_63d',\n",
    "    'treasury_10y_level','spy_above_200ma'\n",
    "])]\n",
    "\n",
    "plot_data = pd.concat([top5_features, macro_features]).drop_duplicates()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(plot_data['Feature'], plot_data['Coefficient']*100,\n",
    "         color=['steelblue']*5 + ['coral']*len(macro_features))\n",
    "plt.xlabel('Feature Importance (%)')\n",
    "plt.title('Random Forest Feature Importance: Top Features vs Macro Variables')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO9lp57g-c33"
   },
   "source": [
    "- elastic net ignored all features\n",
    "- its 60% direction accuracy came from learning 82% bull market dominance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huMjDCxiaKZp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2VxZzmH94jk",
    "outputId": "c18a1c86-263b-4bf5-89db-22fb291147f7"
   },
   "outputs": [],
   "source": [
    "# elastic net positive rate\n",
    "pos_pred = (elnet_pred_df > 0).sum().sum()\n",
    "tot_pred = elnet_pred_df.size\n",
    "pred_pos_rate = pos_pred / tot_pred\n",
    "print(f\"Elastic net positive predictions: {pred_pos_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmAIIIe2XfQ-",
    "outputId": "27d6ec5f-6f0c-4473-be28-5401a5035ad8"
   },
   "outputs": [],
   "source": [
    "# positive rate by sector\n",
    "print(\"\\nPositive by sector:\")\n",
    "print((elnet_pred_df > 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY8RszDkZ4bK"
   },
   "source": [
    "- elastic net ignored all features and predicted 97.1% positive based on its interept\n",
    "- elastic net learned that, on average, sectors go up, so it predicted always up\n",
    "- this explains why random forest feature importance relied heavily on XLE. XLE was the only sector with meaningful variation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkeSuD2_bW-N"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK7ELv3ddC_T"
   },
   "source": [
    "### Lessons learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRtg6hukbb5n"
   },
   "source": [
    "- engineer more sophisticated macro features\n",
    " - momentum features work better than macro features for short term prediction\n",
    " - cross-sectional ranking features didn't help as expected\n",
    " - time horizon mismatch; macro trends need longer time horizon\n",
    "- might have discovered energy sector predictable model\n",
    " - results revealed that XLE momentum and volatility patterns are learnable\n",
    " - energy sector behaves differently from other sectors\n",
    "- market regime matters\n",
    " - 82% bull market is a crucial and decisive factor\n",
    " - proves importance of testing models across different market conditions\n",
    " - reveals how models can learn environmental bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5l7sB8DdGQ-"
   },
   "source": [
    "### Limitation of current approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNgWy2QQdJIv"
   },
   "source": [
    "-\n",
    "- need more and rich data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCbg5G9ddJh4"
   },
   "source": [
    "### Future research/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX-QjwDbdTRc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfD33n45dJkW"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
